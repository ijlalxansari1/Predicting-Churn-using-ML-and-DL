{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccacbe18",
   "metadata": {},
   "source": [
    " # Cell 1 â€“ Load Parsed Sessions from Pickle File\n",
    "  This cell loads the parsed SLAM sessions (slam_sessions.pkl) from the\n",
    "  data/interim folder.\n",
    "  These are the raw token-level session logs we will use to extract metadata such\n",
    "  as user ID, session type, client platform, time spent, and activity days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88ac11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… slam_sessions loaded. Total sessions: 824012\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# Set project root (assuming current script is in a subfolder)\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# Define path to the pickle file\n",
    "parsed_sessions_path = project_root / \"data\" / \"interim\" / \"slam_sessions.pkl\"\n",
    "\n",
    "# Load the pickle file\n",
    "with open(parsed_sessions_path, \"rb\") as f:\n",
    "    slam_sessions = pickle.load(f)\n",
    "\n",
    "print(f\"âœ… slam_sessions loaded. Total sessions: {len(slam_sessions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2484b4",
   "metadata": {},
   "source": [
    " # Cell 2 â€“ Extract Metadata to DataFrame\n",
    " This cell extracts key metadata from each session such as user_id,\n",
    " session_type, client, days, time, etc.\n",
    " We create a structured DataFrame df_sessions and handle missing/null values\n",
    " for numeric fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "996901c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Data Validation Results:\n",
      "âœ… No nulls in key fields\n",
      "âŒ Positive time values\n",
      "âŒ Valid day range\n",
      "âœ… Valid user_ids\n",
      "âœ… Session types present\n",
      "âœ… Client types present\n",
      "\n",
      "âš ï¸ Warning: Some validations failed!\n",
      "Failed checks: ['Positive time values', 'Valid day range']\n",
      "\n",
      "ðŸ“ Metadata saved to: f:\\Bachleros Research\\Rsearch thesis\\Predicting-Churn-using-ML-and-DL\\data\\processed\\parsed_sessions.csv\n",
      "âœ… Total rows saved: 595100\n",
      "\n",
      "ðŸ“Š session_type breakdown:\n",
      " session_type\n",
      "lesson      493236\n",
      "practice     93907\n",
      "test          7957\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ–¥ï¸ client breakdown:\n",
      " client\n",
      "android    416645\n",
      "ios        107590\n",
      "web         70865\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ“ˆ Numeric stats:\n",
      "                 days           time\n",
      "count  595100.000000  595100.000000\n",
      "mean        6.072470      24.693122\n",
      "std         5.631776     766.344798\n",
      "min         0.000000    -156.000000\n",
      "25%         1.307000       5.000000\n",
      "50%         4.355500       9.000000\n",
      "75%         9.284000      17.000000\n",
      "max        28.042000  330554.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_metadata(session: List[str]) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Extract metadata from session lines.\n",
    "    \n",
    "    Args:\n",
    "        session (List[str]): List of session lines\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, any]: Extracted metadata containing:\n",
    "            - prompt: String containing the session prompt\n",
    "            - user_id: Unique identifier for the user\n",
    "            - countries: Country codes\n",
    "            - days: Number of days since first activity\n",
    "            - client: Platform used (web/android/ios)\n",
    "            - session_type: Type of learning session\n",
    "            - format: Session format\n",
    "            - time: Time spent in session\n",
    "    \"\"\"\n",
    "    metadata = {\n",
    "        \"prompt\": \"\", \"user_id\": \"\", \"countries\": \"\", \"days\": 0,\n",
    "        \"client\": \"\", \"session_type\": \"\", \"format\": \"\", \"time\": 0\n",
    "    }\n",
    "    # Extract metadata from session lines\n",
    "    for line in session:\n",
    "        if line.startswith(\"# prompt:\"):\n",
    "            metadata[\"prompt\"] = line.replace(\"# prompt:\", \"\").strip()\n",
    "        elif line.startswith(\"# user:\"):\n",
    "            parts = line.replace(\"# user:\", \"\").strip().split()\n",
    "            metadata[\"user_id\"] = parts[0]\n",
    "            for part in parts[1:]:\n",
    "                if \":\" in part:\n",
    "                    key, value = part.split(\":\")\n",
    "                    if key == \"session\":\n",
    "                        metadata[\"session_type\"] = value\n",
    "                    elif key == \"days\":\n",
    "                        metadata[\"days\"] = value\n",
    "                    elif key in metadata:\n",
    "                        metadata[key] = value\n",
    "    return metadata\n",
    "\n",
    "# Apply extractor to sessions that have prompts\n",
    "parsed_metadata = [\n",
    "    extract_metadata(s) for s in slam_sessions\n",
    "    if any(\"# prompt:\" in line for line in s)\n",
    "]\n",
    "\n",
    "# Build DataFrame\n",
    "df_sessions = pd.DataFrame(parsed_metadata)\n",
    "\n",
    "# Clean up 'time' and 'days' columns\n",
    "df_sessions['time'] = pd.to_numeric(df_sessions['time'].replace(['null', '', None], 0))\n",
    "df_sessions['days'] = pd.to_numeric(df_sessions['days'].replace(['null', '', None], 0))\n",
    "\n",
    "# Add validation function\n",
    "def validate_features(df: pd.DataFrame) -> bool:\n",
    "    \"\"\"\n",
    "    Validate engineered features for data quality.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing session features\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if all validations pass, False otherwise\n",
    "    \"\"\"\n",
    "    checks = {\n",
    "        \"No nulls in key fields\": df[['user_id', 'time', 'days']].notnull().all().all(),\n",
    "        \"Positive time values\": (df['time'] >= 0).all(),\n",
    "        \"Valid day range\": (df['days'] >= 0).all() & (df['days'] <= 14).all(),\n",
    "        \"Valid user_ids\": df['user_id'].astype(str).str.len().gt(0).all(),\n",
    "        \"Session types present\": df['session_type'].notna().any(),\n",
    "        \"Client types present\": df['client'].notna().any()\n",
    "    }\n",
    "    \n",
    "    print(\"\\nðŸ” Data Validation Results:\")\n",
    "    for check, result in checks.items():\n",
    "        print(f\"{'âœ…' if result else 'âŒ'} {check}\")\n",
    "    \n",
    "    if not all(checks.values()):\n",
    "        print(\"\\nâš ï¸ Warning: Some validations failed!\")\n",
    "        failed_checks = [check for check, result in checks.items() if not result]\n",
    "        print(\"Failed checks:\", failed_checks)\n",
    "    \n",
    "    return all(checks.values())\n",
    "\n",
    "# Run validation\n",
    "validation_result = validate_features(df_sessions)\n",
    "\n",
    "# Additional statistics if validation passes\n",
    "if validation_result:\n",
    "    print(\"\\nðŸ“Š Data Quality Metrics:\")\n",
    "    print(f\"Total Sessions: {len(df_sessions):,}\")\n",
    "    print(f\"Unique Users: {df_sessions['user_id'].nunique():,}\")\n",
    "    print(f\"Date Range: {df_sessions['days'].min():.0f} to {df_sessions['days'].max():.0f} days\")\n",
    "    print(f\"Average Session Time: {df_sessions['time'].mean():.2f}\")\n",
    "\n",
    "# Save to CSV\n",
    "output_path = project_root / \"data\" / \"processed\" / \"parsed_sessions.csv\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_sessions.to_csv(output_path, index=False)\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\nðŸ“ Metadata saved to: {output_path}\")\n",
    "print(f\"âœ… Total rows saved: {len(df_sessions)}\\n\")\n",
    "\n",
    "# Inspect value counts\n",
    "print(\"ðŸ“Š session_type breakdown:\\n\", df_sessions['session_type'].value_counts())\n",
    "print(\"\\nðŸ–¥ï¸ client breakdown:\\n\", df_sessions['client'].value_counts())\n",
    "print(\"\\nðŸ“ˆ Numeric stats:\\n\", df_sessions[['days', 'time']].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba1415e",
   "metadata": {},
   "source": [
    "# Cell 3 â€“ Inspect Raw Lines with Session-Type Information\n",
    " This helps verify that session types like \n",
    " correctly tagged in the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90ff680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Checking session lines that might contain 'session_type':\n",
      "\n",
      "ðŸ†• New session:\n",
      "   # user:XEinXf5+  countries:CO  days:0.003  client:web  session:lesson  format:reverse_translate  time:9\n",
      "ðŸ†• New session:\n",
      "   # user:XEinXf5+  countries:CO  days:0.005  client:web  session:lesson  format:reverse_translate  time:12\n",
      "ðŸ†• New session:\n",
      "   # user:XEinXf5+  countries:CO  days:0.008  client:web  session:lesson  format:reverse_translate  time:6\n",
      "ðŸ†• New session:\n",
      "   # user:XEinXf5+  countries:CO  days:0.008  client:web  session:lesson  format:reverse_translate  time:13\n",
      "ðŸ†• New session:\n",
      "   # user:XEinXf5+  countries:CO  days:0.008  client:web  session:lesson  format:reverse_translate  time:16\n",
      "ðŸ†• New session:\n",
      "   # user:XEinXf5+  countries:CO  days:0.011  client:web  session:lesson  format:reverse_translate  time:10\n",
      "ðŸ†• New session:\n",
      "   # user:XEinXf5+  countries:CO  days:0.011  client:web  session:lesson  format:reverse_translate  time:5\n",
      "ðŸ†• New session:\n",
      "   # user:XEinXf5+  countries:CO  days:0.016  client:web  session:lesson  format:reverse_translate  time:11\n",
      "ðŸ†• New session:\n",
      "   # user:XEinXf5+  countries:CO  days:0.016  client:web  session:lesson  format:reverse_translate  time:10\n",
      "ðŸ†• New session:\n",
      "   # user:XEinXf5+  countries:CO  days:0.018  client:web  session:lesson  format:listen  time:5\n"
     ]
    }
   ],
   "source": [
    "# -------------------- CELL 3: Inspect Session Types -------------------\n",
    "print(\"ðŸ” Checking session lines that might contain 'session_type':\\n\")\n",
    "for session in slam_sessions[:10]:\n",
    "    print(\"ðŸ†• New session:\")\n",
    "    for line in session:\n",
    "        if \"session_type\" in line.lower() or \"session:\" in line.lower():\n",
    "            print(\"  \", line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f59af",
   "metadata": {},
   "source": [
    "# Cell 4 â€“ Filter Early Sessions (â‰¤14 Days)\n",
    " We focus only on sessions from the first 14 days of activity per user.\n",
    " This matches our proposalâ€™s scope for predicting churn based on early behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b906d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filtered early sessions: 481271 rows\n"
     ]
    }
   ],
   "source": [
    "# -------------------- CELL 4: Filter Early Sessions -------------------\n",
    "df_cleaned = df_sessions.dropna(subset=[\"time\"])\n",
    "df_cleaned = df_cleaned[df_cleaned[\"time\"] > 0]\n",
    "\n",
    "# IQR filtering for outliers in time\n",
    "Q1 = df_cleaned[\"time\"].quantile(0.25)\n",
    "Q3 = df_cleaned[\"time\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df_cleaned = df_cleaned[(df_cleaned[\"time\"] >= lower_bound) & (df_cleaned[\"time\"] <= upper_bound)]\n",
    "\n",
    "# Normalize session_type\n",
    "df_cleaned[\"session_type\"] = df_cleaned[\"session_type\"].astype(str).str.lower()\n",
    "\n",
    "# Filter early sessions\n",
    "early_sessions = df_cleaned[df_cleaned['days'] <= 14].copy()\n",
    "print(f\"âœ… Filtered early sessions: {early_sessions.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7cc4c6",
   "metadata": {},
   "source": [
    "## ðŸ§® Cell 5 â€“ Feature Engineering: Aggregate Session Data Per User\n",
    "\n",
    "We create user-level features to summarize behavior across sessions. These include:\n",
    "\n",
    "- Average session time, total time, and count of sessions\n",
    "- First and last active day, and list of unique active days\n",
    "- Counts of different `session_type` and `client` (platforms)\n",
    "\n",
    "These features are essential for churn modeling and behavioral analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a56055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… User features created:\n",
      "\n",
      "ðŸ“Š Feature Engineering Summary:\n",
      "Total Users: 2,580\n",
      "Average Sessions per User: 186.54\n",
      "Median Total Time: 1717.00\n",
      "\n",
      "ðŸ“± Platform Usage:\n",
      "android    343655.0\n",
      "ios         79833.0\n",
      "web         57783.0\n",
      "dtype: float64\n",
      "\n",
      "ðŸ“˜ Session Types:\n",
      "lesson      411222.0\n",
      "practice     63666.0\n",
      "test          6383.0\n",
      "dtype: float64\n",
      "\n",
      "âœ… Features saved to: f:\\Bachleros Research\\Rsearch thesis\\Predicting-Churn-using-ML-and-DL\\data\\processed\\user_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Group session data per user to extract behavior features\n",
    "user_features = early_sessions.groupby('user_id').agg({\n",
    "    'time': ['mean', 'sum', 'count'],\n",
    "    'days': ['min', 'max', lambda x: sorted(x.unique())],\n",
    "    'session_type': lambda x: x.value_counts().to_dict(),\n",
    "    'client': lambda x: x.value_counts().to_dict()\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten MultiIndex column names\n",
    "user_features.columns = [\n",
    "    'user_id', 'avg_time', 'total_time', 'session_count',\n",
    "    'first_day', 'last_day', 'active_days',\n",
    "    'session_type_counts', 'client_counts'\n",
    "]\n",
    "\n",
    "print(\"âœ… User features created:\")\n",
    "user_features.head()\n",
    "\n",
    "def print_feature_stats(df: pd.DataFrame):\n",
    "    \"\"\"Print comprehensive feature statistics.\"\"\"\n",
    "    print(\"\\nðŸ“Š Feature Engineering Summary:\")\n",
    "    print(f\"Total Users: {len(df):,}\")\n",
    "    print(f\"Average Sessions per User: {df['session_count'].mean():.2f}\")\n",
    "    print(f\"Median Total Time: {df['total_time'].median():.2f}\")\n",
    "    \n",
    "    print(\"\\nðŸ“± Platform Usage:\")\n",
    "    platform_stats = pd.DataFrame([x for x in df['client_counts']])\n",
    "    print(platform_stats.sum().sort_values(ascending=False))\n",
    "    \n",
    "    print(\"\\nðŸ“˜ Session Types:\")\n",
    "    session_stats = pd.DataFrame([x for x in df['session_type_counts']])\n",
    "    print(session_stats.sum().sort_values(ascending=False))\n",
    "\n",
    "# Call the function\n",
    "print_feature_stats(user_features)\n",
    "\n",
    "# Save engineered features\n",
    "features_path = project_root / \"data\" / \"processed\" / \"user_features.csv\"\n",
    "user_features.to_csv(features_path, index=False)\n",
    "print(f\"\\nâœ… Features saved to: {features_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46b4566",
   "metadata": {},
   "source": [
    "# ðŸ“‹ Data Processing Summary\n",
    "\n",
    "## Quality Checks\n",
    "- Removed null values\n",
    "- Filtered outliers using IQR\n",
    "- Normalized session types\n",
    "- Limited to first 14 days\n",
    "\n",
    "## Feature Set\n",
    "- Time-based: avg_time, total_time, session_count\n",
    "- Activity: first_day, last_day, active_days\n",
    "- Behavior: session_type_counts, client_counts\n",
    "\n",
    "## Next Steps\n",
    "- Feature correlation analysis\n",
    "- Handle categorical variables\n",
    "- Scale numeric features\n",
    "- Split train/test sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
