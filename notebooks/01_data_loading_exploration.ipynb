{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5da89fe",
   "metadata": {},
   "source": [
    "# üì¶ Import Core Libraries and üìÇ Setup and Check Data File   \n",
    "Essential libraries for data loading, exploration, and basic manipulation. \n",
    "Set the project path and check if the raw SLAM training data file exists.  \n",
    "Preview the first few lines if found.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c0cd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train file found.\n",
      "Path: f:\\Bachleros Research\\Rsearch thesis\\Predicting-Churn-using-ML-and-DL\\data\\raw\\data_en_es\\en_es.slam.20190204.train\n",
      "\n",
      "Sample lines:\n",
      "# prompt:Yo soy un ni√±o.\n",
      "# user:XEinXf5+  countries:CO  days:0.003  client:web  session:lesson  format:reverse_translate  time:9\n",
      "DRihrVmh0101  I             PRON    Case=Nom|Number=Sing|Person=1|PronType=Prs|fPOS=PRON++PRP               nsubj        4  0\n",
      "DRihrVmh0102  am            VERB    Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|fPOS=VERB++VBP    cop          4  0\n",
      "DRihrVmh0103  a             DET     Definite=Ind|PronType=Art|fPOS=DET++DT                                  det          4  0\n"
     ]
    }
   ],
   "source": [
    "# -------------------- CELL 1: Import Core Libraries and Setup and Check Data File --------------------\n",
    "# At the top with other imports\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from typing import List\n",
    "import sys  # Add this import\n",
    "\n",
    "# Go up one level from notebooks/ to the project root\n",
    "project_root = Path.cwd().parent\n",
    "base_path = project_root / \"data\" / \"raw\" / \"data_en_es\"\n",
    "train_file = base_path / \"en_es.slam.20190204.train\"\n",
    "\n",
    "# Check if file exists\n",
    "if train_file.exists():\n",
    "    print(\"‚úÖ Train file found.\")\n",
    "    print(\"Path:\", train_file)\n",
    "    with open(train_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        print(\"\\nSample lines:\")\n",
    "        for _ in range(5):\n",
    "            print(file.readline().strip())\n",
    "else:\n",
    "    raise FileNotFoundError(f\"‚ùå Training file not found at {train_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e56507",
   "metadata": {},
   "source": [
    "# üîÑ Parse SLAM Sessions and Save to Pickle  \n",
    "This section parses the raw SLAM training file into structured sessions. Each session is a block of lines separated by an empty line.\n",
    "\n",
    "**Steps**:\n",
    "- Parse each session as a list of lines.\n",
    "- Append all sessions to a main list (`slam_sessions`).\n",
    "- Preview one example session.\n",
    "- Save the parsed data into a `.pkl` file for reuse in later notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a532a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Parsed sessions: 824012\n",
      "\n",
      " Sample Session:\n",
      "# prompt:Yo soy un ni√±o.\n",
      "# user:XEinXf5+  countries:CO  days:0.003  client:web  session:lesson  format:reverse_translate  time:9\n",
      "DRihrVmh0101  I             PRON    Case=Nom|Number=Sing|Person=1|PronType=Prs|fPOS=PRON++PRP               nsubj        4  0\n",
      "DRihrVmh0102  am            VERB    Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|fPOS=VERB++VBP    cop          4  0\n",
      "DRihrVmh0103  a             DET     Definite=Ind|PronType=Art|fPOS=DET++DT                                  det          4  0\n",
      "DRihrVmh0104  boy           NOUN    Number=Sing|fPOS=NOUN++NN                                               ROOT         0  0\n",
      "‚úÖ slam_sessions saved to: f:\\Bachleros Research\\Rsearch thesis\\Predicting-Churn-using-ML-and-DL\\data\\interim\\slam_sessions.pkl\n",
      "‚úÖ Session validation passed\n",
      "\n",
      "üìä Session Statistics:\n",
      "Total Sessions: 824,012\n",
      "Average Lines per Session: 4.91\n",
      "Memory Usage: 6.37 MB\n"
     ]
    }
   ],
   "source": [
    "# -------------------- CELL 3: Parse SLAM Sessions -------------------\n",
    "def parse_slam_sessions(filepath):\n",
    "    sessions = []\n",
    "    current_session = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                if current_session:\n",
    "                    sessions.append(current_session)\n",
    "                    current_session = []\n",
    "            else:\n",
    "                current_session.append(line)\n",
    "        if current_session:\n",
    "            sessions.append(current_session)\n",
    "    return sessions\n",
    "\n",
    "# Parse and preview\n",
    "slam_sessions = parse_slam_sessions(train_file)\n",
    "print(f\"‚úÖ Parsed sessions: {len(slam_sessions)}\")\n",
    "\n",
    "if slam_sessions:\n",
    "    print(\"\\n Sample Session:\")\n",
    "    for line in slam_sessions[0]:\n",
    "        print(line)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No sessions found.\")\n",
    "\n",
    "# Save parsed sessions to disk\n",
    "parsed_sessions_path = project_root / \"data\" / \"interim\" / \"slam_sessions.pkl\"\n",
    "parsed_sessions_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(parsed_sessions_path, \"wb\") as f:\n",
    "    pickle.dump(slam_sessions, f)\n",
    "\n",
    "print(f\"‚úÖ slam_sessions saved to: {parsed_sessions_path}\")\n",
    "\n",
    "# Validate Sessions Structure \n",
    "\n",
    "def validate_sessions(sessions: List[List[str]]) -> bool:\n",
    "    \"\"\"Validate basic session structure.\"\"\"\n",
    "    if not sessions:\n",
    "        return False\n",
    "    \n",
    "    for session in sessions:\n",
    "        if not session or not isinstance(session, list):\n",
    "            return False\n",
    "            \n",
    "    return True\n",
    "\n",
    "# Validate after parsing\n",
    "if not validate_sessions(slam_sessions):\n",
    "    raise ValueError(\"‚ùå Invalid session structure detected\")\n",
    "print(\"‚úÖ Session validation passed\")\n",
    "\n",
    "# Session Stats\n",
    "def print_session_stats():\n",
    "    \"\"\"Print basic statistics about the parsed sessions.\"\"\"\n",
    "    total_sessions = len(slam_sessions)\n",
    "    avg_lines = sum(len(s) for s in slam_sessions) / total_sessions\n",
    "    \n",
    "    print(\"\\nüìä Session Statistics:\")\n",
    "    print(f\"Total Sessions: {total_sessions:,}\")\n",
    "    print(f\"Average Lines per Session: {avg_lines:.2f}\")\n",
    "    print(f\"Memory Usage: {sys.getsizeof(slam_sessions) / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Call the function\n",
    "print_session_stats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965327a3",
   "metadata": {},
   "source": [
    "# üìã Notebook Summary\n",
    "\n",
    "This notebook accomplishes:\n",
    "1. **Data Loading**: Loads raw SLAM session data\n",
    "2. **Data Parsing**: Converts raw text into structured sessions\n",
    "3. **Validation**: Ensures data integrity and structure\n",
    "4. **Statistics**: Provides session count and memory usage\n",
    "5. **Storage**: Saves processed data for next steps\n",
    "\n",
    "Next notebook: `02_preprocessing_feature_eng.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
